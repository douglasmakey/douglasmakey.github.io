<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>How BigCache avoids expensive GC cycles and speeds up concurrent access in Go | KungFu Dev</title><meta name=keywords content="go,cache,bigcache,dev"><meta name=description content="A few days ago, I read an article about BigCache and I was interested to know how they avoided these 2 problems:
 concurrent access expensive GC cycles  I went to their repository and read the code to understand how they achieved it. I think it&rsquo;s amazing so I would like to share it with you.
&lsquo;Fast, concurrent, evicting in-memory cache written to keep big number of entries without impact on performance."><meta name=author content="Me"><link rel=canonical href=https://www.kungfudev.com/posts/how-bigcache-avoids-expensive-gc-cycles-and-speeds-up-concurrent-access-in-go/><link crossorigin=anonymous href=/assets/css/stylesheet.min.ed52a04cba0843fef8297e018b15e8a32a989ea4415133cb8bf77414d3815f7b.css integrity="sha256-7VKgTLoIQ/74KX4BixXooyqYnqRBUTPLi/d0FNOBX3s=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.min.4dcb3c4f38462f66c6b6137227726f5543cb934cca9788f041c087e374491df2.js integrity="sha256-Tcs8TzhGL2bGthNyJ3JvVUPLk0zKl4jwQcCH43RJHfI=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://www.kungfudev.com/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://www.kungfudev.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://www.kungfudev.com/favicon-32x32.png><link rel=apple-touch-icon href=https://www.kungfudev.com/apple-touch-icon.png><link rel=mask-icon href=https://www.kungfudev.com/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://www.kungfudev.com/posts/how-bigcache-avoids-expensive-gc-cycles-and-speeds-up-concurrent-access-in-go/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,o,i,a,t,n,s){e.GoogleAnalyticsObject=t,e[t]=e[t]||function(){(e[t].q=e[t].q||[]).push(arguments)},e[t].l=1*new Date,n=o.createElement(i),s=o.getElementsByTagName(i)[0],n.async=1,n.src=a,s.parentNode.insertBefore(n,s)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="How BigCache avoids expensive GC cycles and speeds up concurrent access in Go"><meta property="og:description" content="A few days ago, I read an article about BigCache and I was interested to know how they avoided these 2 problems:
 concurrent access expensive GC cycles  I went to their repository and read the code to understand how they achieved it. I think it&rsquo;s amazing so I would like to share it with you.
&lsquo;Fast, concurrent, evicting in-memory cache written to keep big number of entries without impact on performance."><meta property="og:type" content="article"><meta property="og:url" content="https://www.kungfudev.com/posts/how-bigcache-avoids-expensive-gc-cycles-and-speeds-up-concurrent-access-in-go/"><meta property="og:image" content="https://www.kungfudev.com/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2019-10-29T00:00:00+00:00"><meta property="article:modified_time" content="2019-10-29T00:00:00+00:00"><meta property="og:site_name" content="I'm Kung Fu Dev"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://www.kungfudev.com/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="How BigCache avoids expensive GC cycles and speeds up concurrent access in Go"><meta name=twitter:description content="A few days ago, I read an article about BigCache and I was interested to know how they avoided these 2 problems:
 concurrent access expensive GC cycles  I went to their repository and read the code to understand how they achieved it. I think it&rsquo;s amazing so I would like to share it with you.
&lsquo;Fast, concurrent, evicting in-memory cache written to keep big number of entries without impact on performance."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://www.kungfudev.com/posts/"},{"@type":"ListItem","position":3,"name":"How BigCache avoids expensive GC cycles and speeds up concurrent access in Go","item":"https://www.kungfudev.com/posts/how-bigcache-avoids-expensive-gc-cycles-and-speeds-up-concurrent-access-in-go/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"How BigCache avoids expensive GC cycles and speeds up concurrent access in Go","name":"How BigCache avoids expensive GC cycles and speeds up concurrent access in Go","description":"A few days ago, I read an article about BigCache and I was interested to know how they avoided these 2 problems:\n concurrent access expensive GC cycles  I went to their repository and read the code to understand how they achieved it. I think it\u0026rsquo;s amazing so I would like to share it with you.\n\u0026lsquo;Fast, concurrent, evicting in-memory cache written to keep big number of entries without impact on performance.","keywords":["go","cache","bigcache","dev"],"articleBody":"A few days ago, I read an article about BigCache and I was interested to know how they avoided these 2 problems:\n concurrent access expensive GC cycles  I went to their repository and read the code to understand how they achieved it. I think it’s amazing so I would like to share it with you.\n‘Fast, concurrent, evicting in-memory cache written to keep big number of entries without impact on performance. BigCache keeps entries on heap but omits GC for them. To achieve that operations on bytes arrays take place, therefore entries (de)serialization in front of the cache will be needed in most use cases.’\nBigCache\nConcurrent access Surely you will need concurrent access, either your program uses goroutines, or you have an HTTP server that allocates goroutines for each request. The most common approach to achieve it would be to use sync.RWMutex in front of the cache access function to ensure that only one goroutine could modify it at a time, but if you use this approach and other goroutine try to make modifications in the cache, the second goroutine would be blocked until the first goroutine unlock the lock, causing undesirable contention periods.\nTo solve this problem, they used shards, but what is a shard? A shard is a struct that contains its instance of the cache with a lock.\nThen they use an array of N shards to distribute the data into them, so when you are going to put or get data from the cache, a shard for that data is chosen by a function that we will talk later, in this way the locks contention can be minimized, because each shard has its lock.\ntype cacheShard struct { items map[uint64]uint32 lock sync.RWMutex array []byte tail int } Expensive GC cycles var map[string]Item The most common pattern in a simple implementation of cache in Go is using a map to save the items, but if you are using a map the garbage collector (GC) will touch every single item of that map during the mark phase, this can be very expensive on the application performance when the map is very large.\nAfter go version 1.5, if you use a map without pointers in keys and values, the GC will omit its content.\nvar map[int]int To avoid this, they used a map without pointers in keys and values, with this the GC will omit the entries in the map and use an array of bytes, where they can put the entry serialized in bytes, then they can store in the map the hashedkey like key and the index of the entry into the array like the value.\nUsing an array of bytes is a smart solution because it only adds one additional object to the mark phase. Since a byte array doesn’t have any pointers (other than the object itself), the GC can mark the entire object in O(1) time.\nLet’s start coding It will be a fairly simple implementation of cache, I avoided eviction, capacity and other things, the code will be simple just to demonstrate how they solved the problems I talked above.\nFirst, the hasher this is a copy \u0026 paste from their repository, you can find the code Here, it is a Hasher which makes no memory allocations.\nhasher.go\npackage main // newDefaultHasher returns a new 64-bit FNV-1a Hasher which makes no memory allocations. // Its Sum64 method will lay the value out in big-endian byte order. // See https://en.wikipedia.org/wiki/Fowler–Noll–Vo_hash_function func newDefaultHasher() fnv64a { return fnv64a{} } type fnv64a struct{} const ( // offset64 FNVa offset basis. See https://en.wikipedia.org/wiki/Fowler–Noll–Vo_hash_function#FNV-1a_hash \toffset64 = 14695981039346656037 // prime64 FNVa prime value. See https://en.wikipedia.org/wiki/Fowler–Noll–Vo_hash_function#FNV-1a_hash \tprime64 = 1099511628211 ) // Sum64 gets the string and returns its uint64 hash value. func (f fnv64a) Sum64(key string) uint64 { var hash uint64 = offset64 for i := 0; i  len(key); i++ { hash ^= uint64(key[i]) hash *= prime64 } return hash } Second, the cache struct contains the logic to get the shards and functions get\u0026set.\nI talked above in the Concurrent access section about a function to choose a shard for the data, to achived this they use the hasher above to hash the key and with the hashedkey get a shard for the the key, to achived that they do a bitwise operation with AND operator, using a mask based on the size of shards to turn off certain bits to get a value into the range of shards.\nhashedkey\u0026mask 0111 AND 1101 (mask) = 0101 cache.go\npackage main var minShards = 1024 type cache struct { shards []*cacheShard hash fnv64a } func newCache() *cache { cache := \u0026cache{ hash: newDefaultHasher(), shards: make([]*cacheShard, minShards), } for i := 0; i  minShards; i++ { cache.shards[i] = initNewShard() } return cache } func (c *cache) getShard(hashedKey uint64) (shard *cacheShard) { return c.shards[hashedKey\u0026uint64(minShards-1)] } func (c *cache) set(key string, value []byte) { hashedKey := c.hash.Sum64(key) shard := c.getShard(hashedKey) shard.set(hashedKey, value) } func (c *cache) get(key string) ([]byte, error) { hashedKey := c.hash.Sum64(key) shard := c.getShard(hashedKey) return shard.get(key, hashedKey) } Finally, where the magic occurs, in each shard have an array of bytes []byte and a map map[uint64]uint32. In the map, they put the index for each entry like value and in the array save the entry in bytes.\nThey use the tail to keep the index in the array of bytes.\nshard.go\npackage main import ( \"encoding/binary\" \"errors\" \"sync\" ) const ( headerEntrySize = 4 defaultValue = 1024 // For this example we use 1024 like default value. ) type cacheShard struct { items map[uint64]uint32 lock sync.RWMutex array []byte tail int headerBuffer []byte } func initNewShard() *cacheShard { return \u0026cacheShard{ items: make(map[uint64]uint32, defaultValue), array: make([]byte, defaultValue), tail: 1, headerBuffer: make([]byte, headerEntrySize), } } func (s *cacheShard) set(hashedKey uint64, entry []byte) { w := wrapEntry(entry) s.lock.Lock() index := s.push(w) s.items[hashedKey] = uint32(index) s.lock.Unlock() } func (s *cacheShard) push(data []byte) int { dataLen := len(data) index := s.tail s.save(data, dataLen) return index } func (s *cacheShard) save(data []byte, len int) { // Put in the first 4 bytes the size of the value \tbinary.LittleEndian.PutUint32(s.headerBuffer, uint32(len)) s.copy(s.headerBuffer, headerEntrySize) s.copy(data, len) } func (s *cacheShard) copy(data []byte, len int) { // Using the tail to keep the order to write in the array \ts.tail += copy(s.array[s.tail:], data[:len]) } func (s *cacheShard) get(key string, hashedKey uint64) ([]byte, error) { s.lock.RLock() itemIndex := int(s.items[hashedKey]) if itemIndex == 0 { s.lock.RUnlock() return nil, errors.New(\"key not found\") } // Read the first 4 bytes after the index, remember these 4 bytes have the size of the value, so \t// you can use this to get the size and get the value in the array using index+blockSize to know until what point \t// you need to read \tblockSize := int(binary.LittleEndian.Uint32(s.array[itemIndex : itemIndex+headerEntrySize])) entry := s.array[itemIndex+headerEntrySize : itemIndex+headerEntrySize+blockSize] s.lock.RUnlock() return readEntry(entry), nil } func readEntry(data []byte) []byte { dst := make([]byte, len(data)) copy(dst, data) return dst } func wrapEntry(entry []byte) []byte { // You can put more information like a timestamp if you want. \tblobLength := len(entry) blob := make([]byte, blobLength) copy(blob, entry) return blob } main.go\npackage main import \"fmt\" func main() { cache := newCache() cache.set(\"key\", []byte(\"the value\")) value, err := cache.get(\"key\") if err != nil { fmt.Println(err) } fmt.Println(string(value)) // OUTPUT: \t// the value } Github Repo\n","wordCount":"1210","inLanguage":"en","datePublished":"2019-10-29T00:00:00Z","dateModified":"2019-10-29T00:00:00Z","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.kungfudev.com/posts/how-bigcache-avoids-expensive-gc-cycles-and-speeds-up-concurrent-access-in-go/"},"publisher":{"@type":"Organization","name":"KungFu Dev","logo":{"@type":"ImageObject","url":"https://www.kungfudev.com/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://www.kungfudev.com accesskey=h title="KungFu Dev (Alt + H)">KungFu Dev</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://www.kungfudev.com/es/ title=Español aria-label=Español>Es</a></li></ul></span></div><ul id=menu><li><a href=https://www.kungfudev.com/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://www.kungfudev.com/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://www.kungfudev.com/archives/ title=Archives><span>Archives</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://www.kungfudev.com>Home</a>&nbsp;»&nbsp;<a href=https://www.kungfudev.com/posts/>Posts</a></div><h1 class=post-title>How BigCache avoids expensive GC cycles and speeds up concurrent access in Go</h1><div class=post-meta><span title="2019-10-29 00:00:00 +0000 UTC">October 29, 2019</span>&nbsp;·&nbsp;6 min&nbsp;·&nbsp;Me&nbsp;|&nbsp;<a href=https://github.com/%3cpath_to_repo%3e/content/posts/how-bigcache-avoids-expensive-gc-cycles-and-speeds-up-concurrent-access-in-go.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=post-content><p>A few days ago, I read an article about BigCache and I was interested to know how they avoided these 2 problems:</p><ul><li>concurrent access</li><li>expensive GC cycles</li></ul><p>I went to their repository and read the code to understand how they achieved it. I think it&rsquo;s amazing so I would like to share it with you.</p><p><em>&lsquo;Fast, concurrent, evicting in-memory cache written to keep big number of entries without impact on performance. BigCache keeps entries on heap but omits GC for them. To achieve that operations on bytes arrays take place, therefore entries (de)serialization in front of the cache will be needed in most use cases.&rsquo;</em></p><p><a href=https://github.com/allegro/bigcache>BigCache</a></p><h2 id=concurrent-access>Concurrent access<a hidden class=anchor aria-hidden=true href=#concurrent-access>#</a></h2><p>Surely you will need concurrent access, either your program uses goroutines, or you have an HTTP server that allocates goroutines for each request. The most common approach to achieve it would be to use sync.RWMutex in front of the cache access function to ensure that only one goroutine could modify it at a time, but if you use this approach and other goroutine try to make modifications in the cache, the second goroutine would be blocked until the first goroutine unlock the lock, causing undesirable contention periods.</p><p>To solve this problem, they used shards, but what is a shard? A shard is a struct that contains its instance of the cache with a lock.</p><p>Then they use an array of N shards to distribute the data into them, so when you are going to put or get data from the cache, a shard for that data is chosen by a function that we will talk later, in this way the locks contention can be minimized, because each shard has its lock.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-go data-lang=go><span class=line><span class=cl><span class=kd>type</span> <span class=nx>cacheShard</span> <span class=kd>struct</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=nx>items</span>        <span class=kd>map</span><span class=p>[</span><span class=kt>uint64</span><span class=p>]</span><span class=kt>uint32</span>
</span></span><span class=line><span class=cl>	<span class=nx>lock</span>         <span class=nx>sync</span><span class=p>.</span><span class=nx>RWMutex</span>
</span></span><span class=line><span class=cl>	<span class=nx>array</span>        <span class=p>[]</span><span class=kt>byte</span>
</span></span><span class=line><span class=cl>	<span class=nx>tail</span>         <span class=kt>int</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><h2 id=expensive-gc-cycles>Expensive GC cycles<a hidden class=anchor aria-hidden=true href=#expensive-gc-cycles>#</a></h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-go data-lang=go><span class=line><span class=cl><span class=kd>var</span> <span class=kd>map</span><span class=p>[</span><span class=kt>string</span><span class=p>]</span><span class=nx>Item</span>
</span></span></code></pre></div><p>The most common pattern in a simple implementation of cache in Go is using a map to save the items, but if you are using a map the garbage collector (GC) will touch every single item of that map during the mark phase, this can be very expensive on the application performance when the map is very large.</p><p><em>After go version 1.5, if you use a map without pointers in keys and values, the GC will omit its content.</em></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-go data-lang=go><span class=line><span class=cl><span class=kd>var</span> <span class=kd>map</span><span class=p>[</span><span class=kt>int</span><span class=p>]</span><span class=kt>int</span>
</span></span></code></pre></div><p>To avoid this, they used a map without pointers in keys and values, with this the GC will omit the entries in the map and use an array of bytes, where they can put the entry serialized in bytes, then they can store in the map the hashedkey like key and the index of the entry into the array like the value.</p><p>Using an array of bytes is a smart solution because it only adds one additional object to the mark phase. Since a byte array doesn’t have any pointers (other than the object itself), the GC can mark the entire object in O(1) time.</p><h1 id=lets-start-coding>Let&rsquo;s start coding<a hidden class=anchor aria-hidden=true href=#lets-start-coding>#</a></h1><p>It will be a fairly simple implementation of cache, I avoided eviction, capacity and other things, the code will be simple just to demonstrate how they solved the problems I talked above.</p><p>First, the hasher this is a <code>copy & paste</code> from their repository, you can find the code <a href=https://github.com/allegro/bigcache/blob/master/fnv.go>Here</a>, it is a <strong>Hasher which makes no memory allocations.</strong></p><p>hasher.go</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-go data-lang=go><span class=line><span class=cl><span class=kn>package</span> <span class=nx>main</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>// newDefaultHasher returns a new 64-bit FNV-1a Hasher which makes no memory allocations.
</span></span></span><span class=line><span class=cl><span class=c1>// Its Sum64 method will lay the value out in big-endian byte order.
</span></span></span><span class=line><span class=cl><span class=c1>// See https://en.wikipedia.org/wiki/Fowler–Noll–Vo_hash_function
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=kd>func</span> <span class=nf>newDefaultHasher</span><span class=p>()</span> <span class=nx>fnv64a</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=k>return</span> <span class=nx>fnv64a</span><span class=p>{}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kd>type</span> <span class=nx>fnv64a</span> <span class=kd>struct</span><span class=p>{}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kd>const</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>	<span class=c1>// offset64 FNVa offset basis. See https://en.wikipedia.org/wiki/Fowler–Noll–Vo_hash_function#FNV-1a_hash
</span></span></span><span class=line><span class=cl><span class=c1></span>	<span class=nx>offset64</span> <span class=p>=</span> <span class=mi>14695981039346656037</span>
</span></span><span class=line><span class=cl>	<span class=c1>// prime64 FNVa prime value. See https://en.wikipedia.org/wiki/Fowler–Noll–Vo_hash_function#FNV-1a_hash
</span></span></span><span class=line><span class=cl><span class=c1></span>	<span class=nx>prime64</span> <span class=p>=</span> <span class=mi>1099511628211</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>// Sum64 gets the string and returns its uint64 hash value.
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=kd>func</span> <span class=p>(</span><span class=nx>f</span> <span class=nx>fnv64a</span><span class=p>)</span> <span class=nf>Sum64</span><span class=p>(</span><span class=nx>key</span> <span class=kt>string</span><span class=p>)</span> <span class=kt>uint64</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=kd>var</span> <span class=nx>hash</span> <span class=kt>uint64</span> <span class=p>=</span> <span class=nx>offset64</span>
</span></span><span class=line><span class=cl>	<span class=k>for</span> <span class=nx>i</span> <span class=o>:=</span> <span class=mi>0</span><span class=p>;</span> <span class=nx>i</span> <span class=p>&lt;</span> <span class=nb>len</span><span class=p>(</span><span class=nx>key</span><span class=p>);</span> <span class=nx>i</span><span class=o>++</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>		<span class=nx>hash</span> <span class=p>^=</span> <span class=nb>uint64</span><span class=p>(</span><span class=nx>key</span><span class=p>[</span><span class=nx>i</span><span class=p>])</span>
</span></span><span class=line><span class=cl>		<span class=nx>hash</span> <span class=o>*=</span> <span class=nx>prime64</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=k>return</span> <span class=nx>hash</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>Second, the cache struct contains the logic to get the shards and functions get&set.</p><p>I talked above in the <strong>Concurrent access</strong> section about a function to choose a shard for the data, to achived this they use the hasher above to hash the key and with the hashedkey get a shard for the the key, to achived that they do a bitwise operation with <code>AND</code> operator, using a mask based on the size of shards to turn off certain bits to get a value into the range of shards.</p><pre tabindex=0><code>hashedkey&amp;mask

    0111
AND 1101  (mask)
  = 0101
</code></pre><p>cache.go</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-go data-lang=go><span class=line><span class=cl><span class=kn>package</span> <span class=nx>main</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kd>var</span> <span class=nx>minShards</span> <span class=p>=</span> <span class=mi>1024</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kd>type</span> <span class=nx>cache</span> <span class=kd>struct</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=nx>shards</span> <span class=p>[]</span><span class=o>*</span><span class=nx>cacheShard</span>
</span></span><span class=line><span class=cl>	<span class=nx>hash</span>   <span class=nx>fnv64a</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kd>func</span> <span class=nf>newCache</span><span class=p>()</span> <span class=o>*</span><span class=nx>cache</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=nx>cache</span> <span class=o>:=</span> <span class=o>&amp;</span><span class=nx>cache</span><span class=p>{</span>
</span></span><span class=line><span class=cl>		<span class=nx>hash</span><span class=p>:</span>   <span class=nf>newDefaultHasher</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>		<span class=nx>shards</span><span class=p>:</span> <span class=nb>make</span><span class=p>([]</span><span class=o>*</span><span class=nx>cacheShard</span><span class=p>,</span> <span class=nx>minShards</span><span class=p>),</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span>
</span></span><span class=line><span class=cl>	<span class=k>for</span> <span class=nx>i</span> <span class=o>:=</span> <span class=mi>0</span><span class=p>;</span> <span class=nx>i</span> <span class=p>&lt;</span> <span class=nx>minShards</span><span class=p>;</span> <span class=nx>i</span><span class=o>++</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>		<span class=nx>cache</span><span class=p>.</span><span class=nx>shards</span><span class=p>[</span><span class=nx>i</span><span class=p>]</span> <span class=p>=</span> <span class=nf>initNewShard</span><span class=p>()</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=k>return</span> <span class=nx>cache</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kd>func</span> <span class=p>(</span><span class=nx>c</span> <span class=o>*</span><span class=nx>cache</span><span class=p>)</span> <span class=nf>getShard</span><span class=p>(</span><span class=nx>hashedKey</span> <span class=kt>uint64</span><span class=p>)</span> <span class=p>(</span><span class=nx>shard</span> <span class=o>*</span><span class=nx>cacheShard</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=k>return</span> <span class=nx>c</span><span class=p>.</span><span class=nx>shards</span><span class=p>[</span><span class=nx>hashedKey</span><span class=o>&amp;</span><span class=nb>uint64</span><span class=p>(</span><span class=nx>minShards</span><span class=o>-</span><span class=mi>1</span><span class=p>)]</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kd>func</span> <span class=p>(</span><span class=nx>c</span> <span class=o>*</span><span class=nx>cache</span><span class=p>)</span> <span class=nf>set</span><span class=p>(</span><span class=nx>key</span> <span class=kt>string</span><span class=p>,</span> <span class=nx>value</span> <span class=p>[]</span><span class=kt>byte</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=nx>hashedKey</span> <span class=o>:=</span> <span class=nx>c</span><span class=p>.</span><span class=nx>hash</span><span class=p>.</span><span class=nf>Sum64</span><span class=p>(</span><span class=nx>key</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=nx>shard</span> <span class=o>:=</span> <span class=nx>c</span><span class=p>.</span><span class=nf>getShard</span><span class=p>(</span><span class=nx>hashedKey</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=nx>shard</span><span class=p>.</span><span class=nf>set</span><span class=p>(</span><span class=nx>hashedKey</span><span class=p>,</span> <span class=nx>value</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kd>func</span> <span class=p>(</span><span class=nx>c</span> <span class=o>*</span><span class=nx>cache</span><span class=p>)</span> <span class=nf>get</span><span class=p>(</span><span class=nx>key</span> <span class=kt>string</span><span class=p>)</span> <span class=p>([]</span><span class=kt>byte</span><span class=p>,</span> <span class=kt>error</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=nx>hashedKey</span> <span class=o>:=</span> <span class=nx>c</span><span class=p>.</span><span class=nx>hash</span><span class=p>.</span><span class=nf>Sum64</span><span class=p>(</span><span class=nx>key</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=nx>shard</span> <span class=o>:=</span> <span class=nx>c</span><span class=p>.</span><span class=nf>getShard</span><span class=p>(</span><span class=nx>hashedKey</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=k>return</span> <span class=nx>shard</span><span class=p>.</span><span class=nf>get</span><span class=p>(</span><span class=nx>key</span><span class=p>,</span> <span class=nx>hashedKey</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>Finally, where the magic occurs, in each shard have an array of bytes <code>[]byte</code> and a map <code>map[uint64]uint32</code>. In the map, they put the index for each entry like value and in the array save the entry in bytes.</p><p>They use the tail to keep the index in the array of bytes.</p><p>shard.go</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-go data-lang=go><span class=line><span class=cl><span class=kn>package</span> <span class=nx>main</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>	<span class=s>&#34;encoding/binary&#34;</span>
</span></span><span class=line><span class=cl>	<span class=s>&#34;errors&#34;</span>
</span></span><span class=line><span class=cl>	<span class=s>&#34;sync&#34;</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kd>const</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>	<span class=nx>headerEntrySize</span> <span class=p>=</span> <span class=mi>4</span>
</span></span><span class=line><span class=cl>	<span class=nx>defaultValue</span>    <span class=p>=</span> <span class=mi>1024</span> <span class=c1>// For this example we use 1024 like default value.
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kd>type</span> <span class=nx>cacheShard</span> <span class=kd>struct</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=nx>items</span>        <span class=kd>map</span><span class=p>[</span><span class=kt>uint64</span><span class=p>]</span><span class=kt>uint32</span>
</span></span><span class=line><span class=cl>	<span class=nx>lock</span>         <span class=nx>sync</span><span class=p>.</span><span class=nx>RWMutex</span>
</span></span><span class=line><span class=cl>	<span class=nx>array</span>        <span class=p>[]</span><span class=kt>byte</span>
</span></span><span class=line><span class=cl>	<span class=nx>tail</span>         <span class=kt>int</span>
</span></span><span class=line><span class=cl>	<span class=nx>headerBuffer</span> <span class=p>[]</span><span class=kt>byte</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kd>func</span> <span class=nf>initNewShard</span><span class=p>()</span> <span class=o>*</span><span class=nx>cacheShard</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=k>return</span> <span class=o>&amp;</span><span class=nx>cacheShard</span><span class=p>{</span>
</span></span><span class=line><span class=cl>		<span class=nx>items</span><span class=p>:</span>        <span class=nb>make</span><span class=p>(</span><span class=kd>map</span><span class=p>[</span><span class=kt>uint64</span><span class=p>]</span><span class=kt>uint32</span><span class=p>,</span> <span class=nx>defaultValue</span><span class=p>),</span>
</span></span><span class=line><span class=cl>		<span class=nx>array</span><span class=p>:</span>        <span class=nb>make</span><span class=p>([]</span><span class=kt>byte</span><span class=p>,</span> <span class=nx>defaultValue</span><span class=p>),</span>
</span></span><span class=line><span class=cl>		<span class=nx>tail</span><span class=p>:</span>         <span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>		<span class=nx>headerBuffer</span><span class=p>:</span> <span class=nb>make</span><span class=p>([]</span><span class=kt>byte</span><span class=p>,</span> <span class=nx>headerEntrySize</span><span class=p>),</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kd>func</span> <span class=p>(</span><span class=nx>s</span> <span class=o>*</span><span class=nx>cacheShard</span><span class=p>)</span> <span class=nf>set</span><span class=p>(</span><span class=nx>hashedKey</span> <span class=kt>uint64</span><span class=p>,</span> <span class=nx>entry</span> <span class=p>[]</span><span class=kt>byte</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=nx>w</span> <span class=o>:=</span> <span class=nf>wrapEntry</span><span class=p>(</span><span class=nx>entry</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=nx>s</span><span class=p>.</span><span class=nx>lock</span><span class=p>.</span><span class=nf>Lock</span><span class=p>()</span>
</span></span><span class=line><span class=cl>	<span class=nx>index</span> <span class=o>:=</span> <span class=nx>s</span><span class=p>.</span><span class=nf>push</span><span class=p>(</span><span class=nx>w</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=nx>s</span><span class=p>.</span><span class=nx>items</span><span class=p>[</span><span class=nx>hashedKey</span><span class=p>]</span> <span class=p>=</span> <span class=nb>uint32</span><span class=p>(</span><span class=nx>index</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=nx>s</span><span class=p>.</span><span class=nx>lock</span><span class=p>.</span><span class=nf>Unlock</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kd>func</span> <span class=p>(</span><span class=nx>s</span> <span class=o>*</span><span class=nx>cacheShard</span><span class=p>)</span> <span class=nf>push</span><span class=p>(</span><span class=nx>data</span> <span class=p>[]</span><span class=kt>byte</span><span class=p>)</span> <span class=kt>int</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=nx>dataLen</span> <span class=o>:=</span> <span class=nb>len</span><span class=p>(</span><span class=nx>data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=nx>index</span> <span class=o>:=</span> <span class=nx>s</span><span class=p>.</span><span class=nx>tail</span>
</span></span><span class=line><span class=cl>	<span class=nx>s</span><span class=p>.</span><span class=nf>save</span><span class=p>(</span><span class=nx>data</span><span class=p>,</span> <span class=nx>dataLen</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=k>return</span> <span class=nx>index</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kd>func</span> <span class=p>(</span><span class=nx>s</span> <span class=o>*</span><span class=nx>cacheShard</span><span class=p>)</span> <span class=nf>save</span><span class=p>(</span><span class=nx>data</span> <span class=p>[]</span><span class=kt>byte</span><span class=p>,</span> <span class=nx>len</span> <span class=kt>int</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=c1>// Put in the first 4 bytes the size of the value
</span></span></span><span class=line><span class=cl><span class=c1></span>	<span class=nx>binary</span><span class=p>.</span><span class=nx>LittleEndian</span><span class=p>.</span><span class=nf>PutUint32</span><span class=p>(</span><span class=nx>s</span><span class=p>.</span><span class=nx>headerBuffer</span><span class=p>,</span> <span class=nb>uint32</span><span class=p>(</span><span class=nx>len</span><span class=p>))</span>
</span></span><span class=line><span class=cl>	<span class=nx>s</span><span class=p>.</span><span class=nb>copy</span><span class=p>(</span><span class=nx>s</span><span class=p>.</span><span class=nx>headerBuffer</span><span class=p>,</span> <span class=nx>headerEntrySize</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=nx>s</span><span class=p>.</span><span class=nb>copy</span><span class=p>(</span><span class=nx>data</span><span class=p>,</span> <span class=nx>len</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kd>func</span> <span class=p>(</span><span class=nx>s</span> <span class=o>*</span><span class=nx>cacheShard</span><span class=p>)</span> <span class=nb>copy</span><span class=p>(</span><span class=nx>data</span> <span class=p>[]</span><span class=kt>byte</span><span class=p>,</span> <span class=nx>len</span> <span class=kt>int</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=c1>// Using the tail to keep the order to write in the array
</span></span></span><span class=line><span class=cl><span class=c1></span>	<span class=nx>s</span><span class=p>.</span><span class=nx>tail</span> <span class=o>+=</span> <span class=nb>copy</span><span class=p>(</span><span class=nx>s</span><span class=p>.</span><span class=nx>array</span><span class=p>[</span><span class=nx>s</span><span class=p>.</span><span class=nx>tail</span><span class=p>:],</span> <span class=nx>data</span><span class=p>[:</span><span class=nx>len</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kd>func</span> <span class=p>(</span><span class=nx>s</span> <span class=o>*</span><span class=nx>cacheShard</span><span class=p>)</span> <span class=nf>get</span><span class=p>(</span><span class=nx>key</span> <span class=kt>string</span><span class=p>,</span> <span class=nx>hashedKey</span> <span class=kt>uint64</span><span class=p>)</span> <span class=p>([]</span><span class=kt>byte</span><span class=p>,</span> <span class=kt>error</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=nx>s</span><span class=p>.</span><span class=nx>lock</span><span class=p>.</span><span class=nf>RLock</span><span class=p>()</span>
</span></span><span class=line><span class=cl>	<span class=nx>itemIndex</span> <span class=o>:=</span> <span class=nb>int</span><span class=p>(</span><span class=nx>s</span><span class=p>.</span><span class=nx>items</span><span class=p>[</span><span class=nx>hashedKey</span><span class=p>])</span>
</span></span><span class=line><span class=cl>	<span class=k>if</span> <span class=nx>itemIndex</span> <span class=o>==</span> <span class=mi>0</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>		<span class=nx>s</span><span class=p>.</span><span class=nx>lock</span><span class=p>.</span><span class=nf>RUnlock</span><span class=p>()</span>
</span></span><span class=line><span class=cl>		<span class=k>return</span> <span class=kc>nil</span><span class=p>,</span> <span class=nx>errors</span><span class=p>.</span><span class=nf>New</span><span class=p>(</span><span class=s>&#34;key not found&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=c1>// Read the first 4 bytes after the index, remember these 4 bytes have the size of the value, so
</span></span></span><span class=line><span class=cl><span class=c1></span>	<span class=c1>// you can use this to get the size and get the value in the array using index+blockSize to know until what point
</span></span></span><span class=line><span class=cl><span class=c1></span>	<span class=c1>// you need to read
</span></span></span><span class=line><span class=cl><span class=c1></span>	<span class=nx>blockSize</span> <span class=o>:=</span> <span class=nb>int</span><span class=p>(</span><span class=nx>binary</span><span class=p>.</span><span class=nx>LittleEndian</span><span class=p>.</span><span class=nf>Uint32</span><span class=p>(</span><span class=nx>s</span><span class=p>.</span><span class=nx>array</span><span class=p>[</span><span class=nx>itemIndex</span> <span class=p>:</span> <span class=nx>itemIndex</span><span class=o>+</span><span class=nx>headerEntrySize</span><span class=p>]))</span>
</span></span><span class=line><span class=cl>	<span class=nx>entry</span> <span class=o>:=</span> <span class=nx>s</span><span class=p>.</span><span class=nx>array</span><span class=p>[</span><span class=nx>itemIndex</span><span class=o>+</span><span class=nx>headerEntrySize</span> <span class=p>:</span> <span class=nx>itemIndex</span><span class=o>+</span><span class=nx>headerEntrySize</span><span class=o>+</span><span class=nx>blockSize</span><span class=p>]</span>
</span></span><span class=line><span class=cl>	<span class=nx>s</span><span class=p>.</span><span class=nx>lock</span><span class=p>.</span><span class=nf>RUnlock</span><span class=p>()</span>
</span></span><span class=line><span class=cl>	<span class=k>return</span> <span class=nf>readEntry</span><span class=p>(</span><span class=nx>entry</span><span class=p>),</span> <span class=kc>nil</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kd>func</span> <span class=nf>readEntry</span><span class=p>(</span><span class=nx>data</span> <span class=p>[]</span><span class=kt>byte</span><span class=p>)</span> <span class=p>[]</span><span class=kt>byte</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=nx>dst</span> <span class=o>:=</span> <span class=nb>make</span><span class=p>([]</span><span class=kt>byte</span><span class=p>,</span> <span class=nb>len</span><span class=p>(</span><span class=nx>data</span><span class=p>))</span>
</span></span><span class=line><span class=cl>	<span class=nb>copy</span><span class=p>(</span><span class=nx>dst</span><span class=p>,</span> <span class=nx>data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=k>return</span> <span class=nx>dst</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kd>func</span> <span class=nf>wrapEntry</span><span class=p>(</span><span class=nx>entry</span> <span class=p>[]</span><span class=kt>byte</span><span class=p>)</span> <span class=p>[]</span><span class=kt>byte</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=c1>// You can put more information like a timestamp if you want.
</span></span></span><span class=line><span class=cl><span class=c1></span>	<span class=nx>blobLength</span> <span class=o>:=</span> <span class=nb>len</span><span class=p>(</span><span class=nx>entry</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=nx>blob</span> <span class=o>:=</span> <span class=nb>make</span><span class=p>([]</span><span class=kt>byte</span><span class=p>,</span> <span class=nx>blobLength</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=nb>copy</span><span class=p>(</span><span class=nx>blob</span><span class=p>,</span> <span class=nx>entry</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=k>return</span> <span class=nx>blob</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>main.go</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-go data-lang=go><span class=line><span class=cl><span class=kn>package</span> <span class=nx>main</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=s>&#34;fmt&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kd>func</span> <span class=nf>main</span><span class=p>()</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=nx>cache</span> <span class=o>:=</span> <span class=nf>newCache</span><span class=p>()</span>
</span></span><span class=line><span class=cl>	<span class=nx>cache</span><span class=p>.</span><span class=nf>set</span><span class=p>(</span><span class=s>&#34;key&#34;</span><span class=p>,</span> <span class=p>[]</span><span class=nb>byte</span><span class=p>(</span><span class=s>&#34;the value&#34;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=nx>value</span><span class=p>,</span> <span class=nx>err</span> <span class=o>:=</span> <span class=nx>cache</span><span class=p>.</span><span class=nf>get</span><span class=p>(</span><span class=s>&#34;key&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=k>if</span> <span class=nx>err</span> <span class=o>!=</span> <span class=kc>nil</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>		<span class=nx>fmt</span><span class=p>.</span><span class=nf>Println</span><span class=p>(</span><span class=nx>err</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=nx>fmt</span><span class=p>.</span><span class=nf>Println</span><span class=p>(</span><span class=nb>string</span><span class=p>(</span><span class=nx>value</span><span class=p>))</span>
</span></span><span class=line><span class=cl>	<span class=c1>// OUTPUT:
</span></span></span><span class=line><span class=cl><span class=c1></span>	<span class=c1>// the value
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=p>}</span>
</span></span></code></pre></div><p><a href=https://github.com/douglasmakey/cache-example>Github Repo</a></p></div><footer class=post-footer><ul class=post-tags><li><a href=https://www.kungfudev.com/tags/go/>go</a></li><li><a href=https://www.kungfudev.com/tags/cache/>cache</a></li><li><a href=https://www.kungfudev.com/tags/bigcache/>bigcache</a></li><li><a href=https://www.kungfudev.com/tags/dev/>dev</a></li></ul><nav class=paginav><a class=prev href=https://www.kungfudev.com/posts/how-to-setup-simple-load-balancing-with-ipvs-demo-with-docker/><span class=title>« Prev Page</span><br><span>How to setup simple load balancing with IPVS, demo with docker</span></a>
<a class=next href=https://www.kungfudev.com/posts/implementation-of-dijkstra-using-heap-in-go/><span class=title>Next Page »</span><br><span>Implementation of Dijkstra using heap in Go</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share How BigCache avoids expensive GC cycles and speeds up concurrent access in Go on twitter" href="https://twitter.com/intent/tweet/?text=How%20BigCache%20avoids%20expensive%20GC%20cycles%20and%20speeds%20up%20concurrent%20access%20in%20Go&url=https%3a%2f%2fwww.kungfudev.com%2fposts%2fhow-bigcache-avoids-expensive-gc-cycles-and-speeds-up-concurrent-access-in-go%2f&hashtags=go%2ccache%2cbigcache%2cdev"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share How BigCache avoids expensive GC cycles and speeds up concurrent access in Go on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fwww.kungfudev.com%2fposts%2fhow-bigcache-avoids-expensive-gc-cycles-and-speeds-up-concurrent-access-in-go%2f&title=How%20BigCache%20avoids%20expensive%20GC%20cycles%20and%20speeds%20up%20concurrent%20access%20in%20Go&summary=How%20BigCache%20avoids%20expensive%20GC%20cycles%20and%20speeds%20up%20concurrent%20access%20in%20Go&source=https%3a%2f%2fwww.kungfudev.com%2fposts%2fhow-bigcache-avoids-expensive-gc-cycles-and-speeds-up-concurrent-access-in-go%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share How BigCache avoids expensive GC cycles and speeds up concurrent access in Go on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fwww.kungfudev.com%2fposts%2fhow-bigcache-avoids-expensive-gc-cycles-and-speeds-up-concurrent-access-in-go%2f&title=How%20BigCache%20avoids%20expensive%20GC%20cycles%20and%20speeds%20up%20concurrent%20access%20in%20Go"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share How BigCache avoids expensive GC cycles and speeds up concurrent access in Go on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fwww.kungfudev.com%2fposts%2fhow-bigcache-avoids-expensive-gc-cycles-and-speeds-up-concurrent-access-in-go%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share How BigCache avoids expensive GC cycles and speeds up concurrent access in Go on whatsapp" href="https://api.whatsapp.com/send?text=How%20BigCache%20avoids%20expensive%20GC%20cycles%20and%20speeds%20up%20concurrent%20access%20in%20Go%20-%20https%3a%2f%2fwww.kungfudev.com%2fposts%2fhow-bigcache-avoids-expensive-gc-cycles-and-speeds-up-concurrent-access-in-go%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share How BigCache avoids expensive GC cycles and speeds up concurrent access in Go on telegram" href="https://telegram.me/share/url?text=How%20BigCache%20avoids%20expensive%20GC%20cycles%20and%20speeds%20up%20concurrent%20access%20in%20Go&url=https%3a%2f%2fwww.kungfudev.com%2fposts%2fhow-bigcache-avoids-expensive-gc-cycles-and-speeds-up-concurrent-access-in-go%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2022 <a href=https://www.kungfudev.com>KungFu Dev</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(t){t.preventDefault();var e=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView({behavior:"smooth"}),e==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${e}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script src=https://getinsights.io/js/insights.js></script>
<script>insights.init("GdLATB2pvNG_hxRs"),insights.trackPages()</script></body></html>